{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import seaborn as sns\n",
    "\n",
    "# from constants import FINE_TUNED_BERT_MODEL_PATH, TRAIN_DATA_CSV, TEST_DATA_CSV, TARGET_SCALER_PATH, MODELS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a22f13b1bc1256",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load the data and add special tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ab5aecccd56610",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 2\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# SLICE: int | None = 10\n",
    "SLICE = None\n",
    "\n",
    "df_train = pd.read_csv(\"train_data.csv\", dtype={\"id\": str})[:SLICE]\n",
    "df_test = pd.read_csv(\"test_data.csv\", dtype={\"id\": str})[:SLICE]\n",
    "\n",
    "# df_train = pd.read_csv(TRAIN_DATA_CSV, dtype={\"unique_id\": str})[:SLICE]\n",
    "# df_test = pd.read_csv(TEST_DATA_CSV, dtype={\"unique_id\": str})[:SLICE]\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb34bf4b52a4432",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"target_scaler.pkl\", \"rb\") as f:\n",
    "    target_scaler = pickle.load(f)\n",
    "\n",
    "# with open(TARGET_SCALER_PATH, \"rb\") as f:\n",
    "#     target_scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c827dd11b7e12",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"dumitrescustefan/bert-base-romanian-uncased-v1\", do_lower_case=True, add_special_tokens=True, max_length=512, padding=True, truncation=True\n",
    ")\n",
    "bert_model = AutoModel.from_pretrained(\"dumitrescustefan/bert-base-romanian-uncased-v1\")\n",
    "bert_model.to(DEVICE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2d2539f10bda5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, ground_truths):\n",
    "    mae = mean_absolute_error(ground_truths, predictions)\n",
    "    mse = mean_squared_error(ground_truths, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(ground_truths, predictions)\n",
    "\n",
    "    return {\"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "\n",
    "def plot_loss_and_metrics(history, metrics_history, SLICE_START=10):\n",
    "    plt.plot(history[\"train_loss\"][SLICE_START:], label=\"train loss\")\n",
    "    plt.plot(history[\"test_loss\"][SLICE_START:], label=\"test loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(metrics_history[\"train_mae\"][SLICE_START:], label=\"train mae\")\n",
    "    plt.plot(metrics_history[\"test_mae\"][SLICE_START:], label=\"test mae\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MAE\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(metrics_history[\"train_rmse\"][SLICE_START:], label=\"train rmse\")\n",
    "    plt.plot(metrics_history[\"test_rmse\"][SLICE_START:], label=\"test rmse\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(metrics_history[\"train_r2\"][SLICE_START:], label=\"train r2\")\n",
    "    plt.plot(metrics_history[\"test_r2\"][SLICE_START:], label=\"test r2\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"R2\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(metrics_history[\"train_mse\"][SLICE_START:], label=\"train mse\")\n",
    "    plt.plot(metrics_history[\"test_mse\"][SLICE_START:], label=\"test mse\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_metrics_table(metrics_history):\n",
    "    headers = [\"Epoch\", \"MAE\", \"RMSE\", \"R2\", \"MSE\"]\n",
    "\n",
    "    # Prepare train data\n",
    "    train_data = [\n",
    "        [\n",
    "            len(metrics_history[\"train_mae\"]) - 1,\n",
    "            f\"{metrics_history['train_mae'][-1]:.5f}\",\n",
    "            f\"{metrics_history['train_rmse'][-1]:.5f}\",\n",
    "            f\"{metrics_history['train_r2'][-1]:.5f}\",\n",
    "            f\"{metrics_history['train_mse'][-1]:.5f}\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Prepare test data\n",
    "    test_data = [\n",
    "        [\n",
    "            len(metrics_history[\"test_mae\"]) - 1,\n",
    "            f\"{metrics_history['test_mae'][-1]:.5f}\",\n",
    "            f\"{metrics_history['test_rmse'][-1]:.5f}\",\n",
    "            f\"{metrics_history['test_r2'][-1]:.5f}\",\n",
    "            f\"{metrics_history['test_mse'][-1]:.5f}\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Print train metrics table\n",
    "    print(\"Train Metrics\")\n",
    "    print(tabulate(train_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "    # Print test metrics table\n",
    "    print(\"\\nTest Metrics\")\n",
    "    print(tabulate(test_data, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceee66e16ce20c2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Tokenize inputs and create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b6fed2770e6cb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        price = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return item, price\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "\n",
    "train_texts = list(df_train[\"description\"])\n",
    "train_prices = list(df_train[\"price_std\"])\n",
    "eval_texts = list(df_test[\"description\"])\n",
    "eval_prices = list(df_test[\"price_std\"])\n",
    "\n",
    "# Tokenizing texts\n",
    "train_encodings = tokenizer(train_texts, max_length=512, truncation=True, padding=True)\n",
    "eval_encodings = tokenizer(eval_texts, max_length=512, truncation=True, padding=True)\n",
    "\n",
    "train_dataset = CustomDataset(train_encodings, train_prices)\n",
    "eval_dataset = CustomDataset(eval_encodings, eval_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32aefd38911256d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b683c0919786b510",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BERTRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTRegressor, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.fc = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask)\n",
    "        outputs = outputs[1]  # Use the output of the [CLS] token\n",
    "        out = self.fc(outputs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642851f5b2173d29",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = BERTRegressor().to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = AdamW(model.parameters(), lr=0.00001)\n",
    "\n",
    "history = {\"train_loss\": [], \"test_loss\": []}\n",
    "metrics_history = {\"train_mae\": [], \"test_mae\": [], \"train_rmse\": [], \"test_rmse\": [], \"train_r2\": [], \"test_r2\": [], \"train_mse\": [], \"test_mse\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce790d726eddd8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    all_train_predictions = []\n",
    "    all_train_ground_truths = []\n",
    "    for texts, prices in tqdm(train_loader):\n",
    "        input_ids = texts[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = texts[\"attention_mask\"].to(DEVICE)\n",
    "        prices = prices.to(DEVICE)\n",
    "        prices = prices.view(-1, 1)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, prices.float())\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        unnorm_outputs = target_scaler.inverse_transform(outputs.cpu().detach().numpy())\n",
    "        unnorm_prices = target_scaler.inverse_transform(prices.cpu().detach().numpy())\n",
    "\n",
    "        all_train_predictions.extend(unnorm_outputs)\n",
    "        all_train_ground_truths.extend(unnorm_prices)\n",
    "\n",
    "    train_metrics = compute_metrics(all_train_predictions, all_train_ground_truths)\n",
    "    metrics_history[\"train_mae\"].append(train_metrics[\"MAE\"])\n",
    "    metrics_history[\"train_mse\"].append(train_metrics[\"MSE\"])\n",
    "    metrics_history[\"train_rmse\"].append(train_metrics[\"RMSE\"])\n",
    "    metrics_history[\"train_r2\"].append(train_metrics[\"R2\"])\n",
    "\n",
    "    avg_train_loss = np.sum(train_losses) / len(train_loader)\n",
    "    history[\"train_loss\"].append(avg_train_loss)\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {avg_train_loss}\")\n",
    "    print(f\"Epoch {epoch + 1}, Train Metrics: {train_metrics}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        validation_losses = []\n",
    "        all_test_predictions = []\n",
    "        all_test_ground_truths = []\n",
    "        for texts, prices in eval_loader:\n",
    "            input_ids = texts[\"input_ids\"].to(DEVICE)\n",
    "            attention_mask = texts[\"attention_mask\"].to(DEVICE)\n",
    "            prices = prices.to(DEVICE)\n",
    "            prices = prices.view(-1, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            val_loss = criterion(outputs, prices.float())\n",
    "\n",
    "            validation_losses.append(val_loss.item())\n",
    "\n",
    "            unnorm_outputs = target_scaler.inverse_transform(outputs.cpu().detach().numpy())\n",
    "            unnorm_prices = target_scaler.inverse_transform(prices.cpu().detach().numpy())\n",
    "\n",
    "            all_test_predictions.extend(unnorm_outputs)\n",
    "            all_test_ground_truths.extend(unnorm_prices)\n",
    "\n",
    "        avg_val_loss = np.sum(validation_losses) / len(eval_loader)\n",
    "        history[\"test_loss\"].append(avg_val_loss)\n",
    "\n",
    "        test_metrics = compute_metrics(all_test_predictions, all_test_ground_truths)\n",
    "        metrics_history[\"test_mae\"].append(test_metrics[\"MAE\"])\n",
    "        metrics_history[\"test_mse\"].append(test_metrics[\"MSE\"])\n",
    "        metrics_history[\"test_rmse\"].append(test_metrics[\"RMSE\"])\n",
    "        metrics_history[\"test_r2\"].append(test_metrics[\"R2\"])\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Validation Loss: {avg_val_loss}\")\n",
    "        print(f\"Epoch {epoch + 1}, Test Metrics: {test_metrics}\")\n",
    "\n",
    "    # torch.save(model.state_dict(), MODELS_PATH / f\"fine_tuned_bert_model_{epoch+1}.pth\")\n",
    "    torch.save(model.state_dict(), f=f\"fine_tuned_bert_model_{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f864bd318788e68",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_loss_and_metrics(history, metrics_history, SLICE_START=0)\n",
    "print_metrics_table(metrics_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee72653b7bd0b02",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "differences = []\n",
    "abs_differences = []\n",
    "gt = []\n",
    "pred = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for texts, prices in eval_loader:\n",
    "        input_ids = texts[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = texts[\"attention_mask\"].to(DEVICE)\n",
    "        prices = prices.to(DEVICE)\n",
    "        prices = prices.view(-1, 1)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "\n",
    "        unnorm_outputs = target_scaler.inverse_transform(outputs.cpu().detach().numpy())\n",
    "        unnorm_prices = target_scaler.inverse_transform(prices.cpu().detach().numpy())\n",
    "\n",
    "        for output, target in zip(unnorm_outputs, unnorm_prices):\n",
    "            diff = output - target\n",
    "            abs_diff = abs(diff)\n",
    "            differences.append(diff)\n",
    "            abs_differences.append(abs_diff)\n",
    "            gt.append(target)\n",
    "            pred.append(output)\n",
    "\n",
    "# Plotting the differences\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(differences, marker=\"o\", linestyle=\"-\", markersize=4)\n",
    "plt.title(\"Differences between Predictions and Ground Truth\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Prediction - Ground Truth\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "sns.regplot(x=gt, y=pred, ci=None, scatter=True, line_kws={\"color\": \"red\"})\n",
    "\n",
    "# calculate the average difference\n",
    "average_abs_diff = sum(abs_differences) / len(abs_differences)\n",
    "print(f\"Average absolute difference: {average_abs_diff:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df78ce12a3cbde3f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), f=FINE_TUNED_BERT_MODEL_PATH)\n",
    "torch.save(model.state_dict(), f=\"fine_tuned_bert_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5be11a57464fd3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Inference example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc01da7c43eeac9b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"dumitrescustefan/bert-base-romanian-uncased-v1\", do_lower_case=True,\n",
    "#                                           add_special_tokens=True, max_length=512, padding=True, truncation=True)\n",
    "# bert_model = AutoModel.from_pretrained(\"dumitrescustefan/bert-base-romanian-uncased-v1\")\n",
    "# bert_model.to(DEVICE)\n",
    "#\n",
    "#\n",
    "# class BERTRegressor(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(BERTRegressor, self).__init__()\n",
    "#         self.bert = bert_model\n",
    "#         self.fc = nn.Linear(768, 1)\n",
    "#\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         outputs = self.bert(input_ids, attention_mask)\n",
    "#         outputs = outputs[1]  # Use the output of the [CLS] token\n",
    "#         return outputs\n",
    "#\n",
    "#\n",
    "# model = BERTRegressor().to(DEVICE)\n",
    "#\n",
    "# model.load_state_dict(torch.load(FINE_TUNED_BERT_MODEL_PATH))\n",
    "# model.to(DEVICE)\n",
    "# model.eval()\n",
    "#\n",
    "# with torch.no_grad():\n",
    "#     for texts, prices in eval_loader:\n",
    "#         input_ids = texts[\"input_ids\"].to(DEVICE)\n",
    "#         attention_mask = texts[\"attention_mask\"].to(DEVICE)\n",
    "#         prices = prices.to(DEVICE)\n",
    "#\n",
    "#         outputs = model(input_ids, attention_mask)\n",
    "#\n",
    "#         embeddings = outputs.cpu().detach().numpy()\n",
    "#         print(embeddings.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
