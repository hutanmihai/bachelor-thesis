{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from core.src.constants import IMAGES_PATH, TRAIN_DATA_CSV, TEST_DATA_CSV\n",
    "from PIL import Image\n",
    "import timm\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "\n",
    "model = timm.create_model(\"fastvit_t8.apple_in1k\", pretrained=True, num_classes=0)\n",
    "# model.head = nn.Linear(model.num_features, 1)  # change head to regression\n",
    "model.head = nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(model.num_features, 1),\n",
    ")  # change head to regression\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3a6dd38a10a4d99",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, prices, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.prices = prices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx])\n",
    "        price = self.prices[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, price\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_DATA_CSV, dtype={\"unique_id\": str})\n",
    "df_test = pd.read_csv(TEST_DATA_CSV, dtype={\"unique_id\": str})\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_images = df_train[\"unique_id\"].values\n",
    "train_images = [IMAGES_PATH / path / \"00.png\" for path in train_images][:10000]\n",
    "\n",
    "test_images = df_test[\"unique_id\"].values\n",
    "test_images = [IMAGES_PATH / path / \"00.png\" for path in test_images][:10000]\n",
    "\n",
    "train_dataset = CustomDataset(\n",
    "    image_paths=train_images,\n",
    "    prices=df_train[\"price\"].values,\n",
    "    transform=transforms,\n",
    ")\n",
    "\n",
    "test_dataset = CustomDataset(\n",
    "    image_paths=test_images,\n",
    "    prices=df_test[\"price\"].values,\n",
    "    transform=transforms,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac8c09af9d677c80",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dba241bbd0846e7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.train()\n",
    "num_epochs = 10  # or more depending on convergence\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, prices in train_loader:\n",
    "        images = images.to(device)\n",
    "        prices = prices.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(images).squeeze()  # Squeeze is used to remove extra dim if any at output\n",
    "        loss = criterion(predictions, prices.float())\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc64b962c78f387f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    for images, prices in test_loader:\n",
    "        images = images.to(device)\n",
    "        prices = prices.to(device)\n",
    "\n",
    "        predictions = model(images).squeeze()\n",
    "        loss = criterion(predictions, prices.float())\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Test Loss: {total_loss / len(test_loader):.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1479f1c7736ddd11",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
