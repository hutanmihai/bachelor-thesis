{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-17T13:27:16.534420Z",
     "start_time": "2024-04-17T13:27:16.191282Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, mean_squared_log_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"rocar_train.csv\")\n",
    "df_test = pd.read_csv(\"rocar_test.csv\")\n",
    "\n",
    "X_train = df_train.drop(columns=[\"price\"])\n",
    "y_train = df_train[\"price\"]\n",
    "X_test = df_test.drop(columns=[\"price\"])\n",
    "y_test = df_test[\"price\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T13:27:16.573339Z",
     "start_time": "2024-04-17T13:27:16.535469Z"
    }
   },
   "id": "1dc5e22b163062f1",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 33/42 [01:36<00:14,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantileRegressor model failed to execute\n",
      "Solver interior-point is not anymore available in SciPy >= 1.11.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 40/42 [01:52<00:03,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 20016, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 15801.171463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [01:53<00:00,  2.70s/it]\n"
     ]
    }
   ],
   "source": [
    "reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=mean_absolute_error)\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T13:29:10.076603Z",
     "start_time": "2024-04-17T13:27:16.574001Z"
    }
   },
   "id": "65e678b562bfa9f5",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                               Adjusted R-Squared  R-Squared      RMSE  \\\nModel                                                                    \nXGBRegressor                                 0.94       0.94   2344.69   \nLGBMRegressor                                0.93       0.93   2398.79   \nHistGradientBoostingRegressor                0.93       0.93   2400.40   \nExtraTreesRegressor                          0.93       0.93   2452.07   \nRandomForestRegressor                        0.93       0.93   2454.92   \nBaggingRegressor                             0.92       0.92   2553.91   \nGradientBoostingRegressor                    0.91       0.91   2801.57   \nKNeighborsRegressor                          0.91       0.91   2850.44   \nDecisionTreeRegressor                        0.88       0.88   3253.27   \nExtraTreeRegressor                           0.87       0.87   3302.87   \nMLPRegressor                                 0.86       0.87   3418.37   \nPoissonRegressor                             0.85       0.85   3564.51   \nTransformedTargetRegressor                   0.84       0.84   3730.11   \nLinearRegression                             0.84       0.84   3730.11   \nLars                                         0.84       0.84   3730.11   \nRidge                                        0.84       0.84   3730.12   \nLasso                                        0.84       0.84   3730.13   \nBayesianRidge                                0.84       0.84   3730.13   \nLassoLarsIC                                  0.84       0.84   3730.13   \nLassoLars                                    0.84       0.84   3730.13   \nRidgeCV                                      0.84       0.84   3730.15   \nLassoCV                                      0.84       0.84   3730.33   \nLarsCV                                       0.84       0.84   3730.36   \nLassoLarsCV                                  0.84       0.84   3730.36   \nSGDRegressor                                 0.84       0.84   3732.30   \nHuberRegressor                               0.84       0.84   3762.99   \nPassiveAggressiveRegressor                   0.83       0.83   3796.10   \nOrthogonalMatchingPursuitCV                  0.83       0.83   3846.66   \nRANSACRegressor                              0.81       0.81   4029.83   \nElasticNet                                   0.81       0.81   4096.03   \nGammaRegressor                               0.78       0.78   4390.05   \nTweedieRegressor                             0.76       0.76   4550.24   \nAdaBoostRegressor                            0.74       0.74   4706.29   \nLinearSVR                                    0.60       0.60   5874.91   \nOrthogonalMatchingPursuit                    0.45       0.46   6868.91   \nElasticNetCV                                 0.42       0.42   7062.78   \nSVR                                          0.17       0.17   8483.56   \nNuSVR                                        0.16       0.17   8499.92   \nDummyRegressor                              -0.00      -0.00   9311.33   \nKernelRidge                                 -2.05      -2.04  16230.97   \nGaussianProcessRegressor                 -6820.37   -6805.37 767987.08   \n\n                               Time Taken  mean_absolute_error  \nModel                                                           \nXGBRegressor                         0.37              1624.16  \nLGBMRegressor                        0.56              1676.10  \nHistGradientBoostingRegressor        0.76              1677.69  \nExtraTreesRegressor                  2.93              1638.03  \nRandomForestRegressor                4.31              1636.28  \nBaggingRegressor                     0.43              1717.99  \nGradientBoostingRegressor            1.38              2000.96  \nKNeighborsRegressor                  0.24              1956.68  \nDecisionTreeRegressor                0.07              2170.72  \nExtraTreeRegressor                   0.04              2167.76  \nMLPRegressor                         7.10              2514.53  \nPoissonRegressor                     0.05              2387.89  \nTransformedTargetRegressor           0.01              2857.62  \nLinearRegression                     0.01              2857.62  \nLars                                 0.02              2857.62  \nRidge                                0.01              2857.60  \nLasso                                0.01              2857.57  \nBayesianRidge                        0.01              2857.55  \nLassoLarsIC                          0.01              2857.58  \nLassoLars                            0.01              2857.57  \nRidgeCV                              0.03              2857.45  \nLassoCV                              0.06              2857.16  \nLarsCV                               0.03              2857.13  \nLassoLarsCV                          0.03              2857.13  \nSGDRegressor                         0.03              2860.41  \nHuberRegressor                       0.07              2813.06  \nPassiveAggressiveRegressor           0.03              2809.95  \nOrthogonalMatchingPursuitCV          0.04              2942.67  \nRANSACRegressor                      0.12              2954.71  \nElasticNet                           0.02              3015.48  \nGammaRegressor                       0.04              3134.91  \nTweedieRegressor                     0.12              3382.85  \nAdaBoostRegressor                    0.76              3990.11  \nLinearSVR                            0.01              3988.72  \nOrthogonalMatchingPursuit            0.01              5324.54  \nElasticNetCV                         0.08              5638.94  \nSVR                                 11.95              6337.33  \nNuSVR                               11.63              6691.79  \nDummyRegressor                       0.01              7589.71  \nKernelRidge                         23.11             15796.64  \nGaussianProcessRegressor            46.90            194475.04  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Adjusted R-Squared</th>\n      <th>R-Squared</th>\n      <th>RMSE</th>\n      <th>Time Taken</th>\n      <th>mean_absolute_error</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>XGBRegressor</th>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>2344.69</td>\n      <td>0.37</td>\n      <td>1624.16</td>\n    </tr>\n    <tr>\n      <th>LGBMRegressor</th>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>2398.79</td>\n      <td>0.56</td>\n      <td>1676.10</td>\n    </tr>\n    <tr>\n      <th>HistGradientBoostingRegressor</th>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>2400.40</td>\n      <td>0.76</td>\n      <td>1677.69</td>\n    </tr>\n    <tr>\n      <th>ExtraTreesRegressor</th>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>2452.07</td>\n      <td>2.93</td>\n      <td>1638.03</td>\n    </tr>\n    <tr>\n      <th>RandomForestRegressor</th>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>2454.92</td>\n      <td>4.31</td>\n      <td>1636.28</td>\n    </tr>\n    <tr>\n      <th>BaggingRegressor</th>\n      <td>0.92</td>\n      <td>0.92</td>\n      <td>2553.91</td>\n      <td>0.43</td>\n      <td>1717.99</td>\n    </tr>\n    <tr>\n      <th>GradientBoostingRegressor</th>\n      <td>0.91</td>\n      <td>0.91</td>\n      <td>2801.57</td>\n      <td>1.38</td>\n      <td>2000.96</td>\n    </tr>\n    <tr>\n      <th>KNeighborsRegressor</th>\n      <td>0.91</td>\n      <td>0.91</td>\n      <td>2850.44</td>\n      <td>0.24</td>\n      <td>1956.68</td>\n    </tr>\n    <tr>\n      <th>DecisionTreeRegressor</th>\n      <td>0.88</td>\n      <td>0.88</td>\n      <td>3253.27</td>\n      <td>0.07</td>\n      <td>2170.72</td>\n    </tr>\n    <tr>\n      <th>ExtraTreeRegressor</th>\n      <td>0.87</td>\n      <td>0.87</td>\n      <td>3302.87</td>\n      <td>0.04</td>\n      <td>2167.76</td>\n    </tr>\n    <tr>\n      <th>MLPRegressor</th>\n      <td>0.86</td>\n      <td>0.87</td>\n      <td>3418.37</td>\n      <td>7.10</td>\n      <td>2514.53</td>\n    </tr>\n    <tr>\n      <th>PoissonRegressor</th>\n      <td>0.85</td>\n      <td>0.85</td>\n      <td>3564.51</td>\n      <td>0.05</td>\n      <td>2387.89</td>\n    </tr>\n    <tr>\n      <th>TransformedTargetRegressor</th>\n      <td>0.84</td>\n      <td>0.84</td>\n      <td>3730.11</td>\n      <td>0.01</td>\n      <td>2857.62</td>\n    </tr>\n    <tr>\n      <th>LinearRegression</th>\n      <td>0.84</td>\n      <td>0.84</td>\n      <td>3730.11</td>\n      <td>0.01</td>\n      <td>2857.62</td>\n    </tr>\n    <tr>\n      <th>Lars</th>\n      <td>0.84</td>\n      <td>0.84</td>\n      <td>3730.11</td>\n      <td>0.02</td>\n      <td>2857.62</td>\n    </tr>\n    <tr>\n      <th>Ridge</th>\n      <td>0.84</td>\n      <td>0.84</td>\n      <td>3730.12</td>\n      <td>0.01</td>\n      <td>2857.60</td>\n    </tr>\n    <tr>\n      <th>Lasso</th>\n      <td>0.84</td>\n      <td>0.84</td>\n      <td>3730.13</td>\n      <td>0.01</td>\n      <td>2857.57</td>\n    </tr>\n    <tr>\n      <th>BayesianRidge</th>\n      <td>0.84</td>\n      <td>0.84</td>\n      <td>3730.13</td>\n      <td>0.01</td>\n      <td>2857.55</td>\n    </tr>\n    <tr>\n      <th>LassoLarsIC</th>\n      <td>0.84</td>\n      <td>0.84</td>\n      <td>3730.13</td>\n      <td>0.01</td>\n      <td>2857.58</td>\n    </tr>\n    <tr>\n      <th>LassoLars</th>\n      <td>0.84</td>\n      <td>0.84</td>\n      <td>3730.13</td>\n      <td>0.01</td>\n      <td>2857.57</td>\n    </tr>\n    <tr>\n      <th>RidgeCV</th>\n      <td>0.84</td>\n      <td>0.84</td>\n      <td>3730.15</td>\n      <td>0.03</td>\n      <td>2857.45</td>\n    </tr>\n    <tr>\n      <th>LassoCV</th>\n      <td>0.84</td>\n      <td>0.84</td>\n      <td>3730.33</td>\n      <td>0.06</td>\n      <td>2857.16</td>\n    </tr>\n    <tr>\n      <th>LarsCV</th>\n      <td>0.84</td>\n      <td>0.84</td>\n      <td>3730.36</td>\n      <td>0.03</td>\n      <td>2857.13</td>\n    </tr>\n    <tr>\n      <th>LassoLarsCV</th>\n      <td>0.84</td>\n      <td>0.84</td>\n      <td>3730.36</td>\n      <td>0.03</td>\n      <td>2857.13</td>\n    </tr>\n    <tr>\n      <th>SGDRegressor</th>\n      <td>0.84</td>\n      <td>0.84</td>\n      <td>3732.30</td>\n      <td>0.03</td>\n      <td>2860.41</td>\n    </tr>\n    <tr>\n      <th>HuberRegressor</th>\n      <td>0.84</td>\n      <td>0.84</td>\n      <td>3762.99</td>\n      <td>0.07</td>\n      <td>2813.06</td>\n    </tr>\n    <tr>\n      <th>PassiveAggressiveRegressor</th>\n      <td>0.83</td>\n      <td>0.83</td>\n      <td>3796.10</td>\n      <td>0.03</td>\n      <td>2809.95</td>\n    </tr>\n    <tr>\n      <th>OrthogonalMatchingPursuitCV</th>\n      <td>0.83</td>\n      <td>0.83</td>\n      <td>3846.66</td>\n      <td>0.04</td>\n      <td>2942.67</td>\n    </tr>\n    <tr>\n      <th>RANSACRegressor</th>\n      <td>0.81</td>\n      <td>0.81</td>\n      <td>4029.83</td>\n      <td>0.12</td>\n      <td>2954.71</td>\n    </tr>\n    <tr>\n      <th>ElasticNet</th>\n      <td>0.81</td>\n      <td>0.81</td>\n      <td>4096.03</td>\n      <td>0.02</td>\n      <td>3015.48</td>\n    </tr>\n    <tr>\n      <th>GammaRegressor</th>\n      <td>0.78</td>\n      <td>0.78</td>\n      <td>4390.05</td>\n      <td>0.04</td>\n      <td>3134.91</td>\n    </tr>\n    <tr>\n      <th>TweedieRegressor</th>\n      <td>0.76</td>\n      <td>0.76</td>\n      <td>4550.24</td>\n      <td>0.12</td>\n      <td>3382.85</td>\n    </tr>\n    <tr>\n      <th>AdaBoostRegressor</th>\n      <td>0.74</td>\n      <td>0.74</td>\n      <td>4706.29</td>\n      <td>0.76</td>\n      <td>3990.11</td>\n    </tr>\n    <tr>\n      <th>LinearSVR</th>\n      <td>0.60</td>\n      <td>0.60</td>\n      <td>5874.91</td>\n      <td>0.01</td>\n      <td>3988.72</td>\n    </tr>\n    <tr>\n      <th>OrthogonalMatchingPursuit</th>\n      <td>0.45</td>\n      <td>0.46</td>\n      <td>6868.91</td>\n      <td>0.01</td>\n      <td>5324.54</td>\n    </tr>\n    <tr>\n      <th>ElasticNetCV</th>\n      <td>0.42</td>\n      <td>0.42</td>\n      <td>7062.78</td>\n      <td>0.08</td>\n      <td>5638.94</td>\n    </tr>\n    <tr>\n      <th>SVR</th>\n      <td>0.17</td>\n      <td>0.17</td>\n      <td>8483.56</td>\n      <td>11.95</td>\n      <td>6337.33</td>\n    </tr>\n    <tr>\n      <th>NuSVR</th>\n      <td>0.16</td>\n      <td>0.17</td>\n      <td>8499.92</td>\n      <td>11.63</td>\n      <td>6691.79</td>\n    </tr>\n    <tr>\n      <th>DummyRegressor</th>\n      <td>-0.00</td>\n      <td>-0.00</td>\n      <td>9311.33</td>\n      <td>0.01</td>\n      <td>7589.71</td>\n    </tr>\n    <tr>\n      <th>KernelRidge</th>\n      <td>-2.05</td>\n      <td>-2.04</td>\n      <td>16230.97</td>\n      <td>23.11</td>\n      <td>15796.64</td>\n    </tr>\n    <tr>\n      <th>GaussianProcessRegressor</th>\n      <td>-6820.37</td>\n      <td>-6805.37</td>\n      <td>767987.08</td>\n      <td>46.90</td>\n      <td>194475.04</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T13:29:10.091467Z",
     "start_time": "2024-04-17T13:29:10.079462Z"
    }
   },
   "id": "d862e4b16fdfc282",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1639.7261727941832\n",
      "R2: 0.9301008832800457\n",
      "MSE: 6057085.677730238\n",
      "MSLE: 0.02404403153174699\n",
      "MAPE: 0.11432699730830237\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R2: {r2}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"MSLE: {msle}\")\n",
    "print(f\"MAPE: {mape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T13:29:14.380566Z",
     "start_time": "2024-04-17T13:29:10.092294Z"
    }
   },
   "id": "c71d7d4f82b4747e",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T13:29:14.382668Z",
     "start_time": "2024-04-17T13:29:14.381370Z"
    }
   },
   "id": "5c02231c8cdcf0",
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
