{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from constants import (\n",
    "    TRAIN_DATA_CSV,\n",
    "    TEST_DATA_CSV,\n",
    "    MULTIMODAL_MODEL_PATH,\n",
    "    FINE_TUNED_FASTVIT_MODEL_PATH,\n",
    "    FINE_TUNED_BERT_MODEL_PATH,\n",
    "    TARGET_SCALER_PATH,\n",
    "    IMAGES_PATH,\n",
    ")\n",
    "from core.src.utils.metrics import compute_metrics\n",
    "from core.src.utils.plots import plot_loss_and_metrics, print_metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "SLICE: int | None = 5000\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_DATA_CSV, dtype={\"unique_id\": str})[:SLICE]\n",
    "df_test = pd.read_csv(TEST_DATA_CSV, dtype={\"unique_id\": str})[:SLICE]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with open(TARGET_SCALER_PATH, \"rb\") as f:\n",
    "    target_scaler = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80b0b128efc89ffd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fastvit = timm.create_model(\"fastvit_t8.apple_in1k\", pretrained=True, num_classes=0)\n",
    "\n",
    "fastvit.head = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Flatten(), nn.Linear(fastvit.num_features, 1))\n",
    "\n",
    "fastvit.load_state_dict(torch.load(FINE_TUNED_FASTVIT_MODEL_PATH))\n",
    "fastvit.to(device)\n",
    "\n",
    "data_config = timm.data.resolve_model_data_config(fastvit)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "\n",
    "class FastViTEmbedding(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(FastViTEmbedding, self).__init__()\n",
    "        self.model = model\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Assuming the embeddings you want are just before the head.\n",
    "        # This accesses the last layer before the regression head.\n",
    "        x = self.model.forward_features(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "fastvit_model = FastViTEmbedding(fastvit).to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d1f850568f383e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"dumitrescustefan/bert-base-romanian-uncased-v1\", do_lower_case=True, add_special_tokens=True, max_length=512, padding=True, truncation=True\n",
    ")\n",
    "bert_model = AutoModel.from_pretrained(\"dumitrescustefan/bert-base-romanian-uncased-v1\")\n",
    "bert_model.to(device)\n",
    "\n",
    "\n",
    "class BERTRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTRegressor, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.fc = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask)\n",
    "        outputs = outputs[1]  # Use the output of the [CLS] token\n",
    "        return outputs\n",
    "\n",
    "\n",
    "bert_model = BERTRegressor().to(device)\n",
    "\n",
    "bert_model.load_state_dict(torch.load(FINE_TUNED_BERT_MODEL_PATH))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7515c44673db8f89",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_images = df_train[\"unique_id\"].values\n",
    "train_images = [IMAGES_PATH / f\"{path}.png\" for path in train_images]\n",
    "\n",
    "test_images = df_test[\"unique_id\"].values\n",
    "test_images = [IMAGES_PATH / f\"{path}.png\" for path in test_images]\n",
    "\n",
    "train_encodings = tokenizer(df_train[\"input\"].tolist(), padding=True, truncation=True, max_length=512)\n",
    "test_encodings = tokenizer(df_test[\"input\"].tolist(), padding=True, truncation=True, max_length=512)\n",
    "\n",
    "STRUCTURED_COLUMNS = [\n",
    "    \"km\",\n",
    "    \"putere\",\n",
    "    \"capacitate cilindrica\",\n",
    "    \"anul produc»õiei\",\n",
    "    \"marca\",\n",
    "    \"model\",\n",
    "    \"combustibil\",\n",
    "    \"tip caroserie\",\n",
    "    \"firma\",\n",
    "    \"is_automatic\",\n",
    "]\n",
    "\n",
    "train_structured_data = df_train[STRUCTURED_COLUMNS].to_numpy()\n",
    "test_structured_data = df_test[STRUCTURED_COLUMNS].to_numpy()\n",
    "\n",
    "train_targets = df_train[\"price_std\"].to_numpy()\n",
    "test_targets = df_test[\"price_std\"].to_numpy()\n",
    "\n",
    "print(f\"Train images: {len(train_images)}\")\n",
    "print(f\"Train encodings: {len(train_encodings['input_ids'])}\")\n",
    "print(f\"Train structured data: {train_structured_data.shape}\")\n",
    "print(f\"Train targets: {train_targets.shape}\")\n",
    "\n",
    "print(f\"Test images: {len(test_images)}\")\n",
    "print(f\"Test encodings: {len(test_encodings['input_ids'])}\")\n",
    "print(f\"Test structured data: {test_structured_data.shape}\")\n",
    "print(f\"Test targets: {test_targets.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f10674caa124d9ce",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, images_paths, encodings, structured_data, targets):\n",
    "        self.images_paths = images_paths\n",
    "        self.encodings = encodings\n",
    "        self.structured_data = structured_data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.images_paths[idx])\n",
    "        image = transforms(image)\n",
    "        input_ids = torch.tensor(self.encodings[\"input_ids\"][idx])\n",
    "        attention_mask = torch.tensor(self.encodings[\"attention_mask\"][idx])\n",
    "        structured_data = torch.tensor(self.structured_data[idx]).float()\n",
    "        target = torch.tensor(self.targets[idx]).float()\n",
    "\n",
    "        return image, input_ids, attention_mask, structured_data, target"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8c06ddeb04841b3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "train_dataset = MultimodalDataset(train_images, train_encodings, train_structured_data, train_targets)\n",
    "test_dataset = MultimodalDataset(test_images, test_encodings, test_structured_data, test_targets)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cb4fa0a7108d272",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, fastvit_model, bert_model):\n",
    "        super(MultiModalModel, self).__init__()\n",
    "        self.fastvit_model = fastvit_model\n",
    "        self.bert_model = bert_model\n",
    "        self.fc = nn.Linear(768 + 768 + 10, 1)\n",
    "        # self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, image, input_ids, attention_mask, structured_data):\n",
    "        fastvit_embedding = self.fastvit_model(image)\n",
    "        bert_embedding = self.bert_model(input_ids, attention_mask)\n",
    "        x = torch.cat([fastvit_embedding, bert_embedding, structured_data], dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74159cb0f3e1dd45",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "multimodal_model = MultiModalModel(fastvit_model, bert_model).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(multimodal_model.parameters(), lr=0.00001)\n",
    "\n",
    "history = {\"train_loss\": [], \"test_loss\": []}\n",
    "metrics_history = {\"train_mae\": [], \"test_mae\": [], \"train_rmse\": [], \"test_rmse\": [], \"train_r2\": [], \"test_r2\": [], \"train_mse\": [], \"test_mse\": []}\n",
    "\n",
    "multimodal_model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41048aeb340c788a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def print_model_statuses():\n",
    "    print(f\"Core FastViT model: {multimodal_model.fastvit_model.model.training}\")\n",
    "    print(f\"Core BERT model: {multimodal_model.bert_model.bert.training}\")\n",
    "\n",
    "    print(f\"FastVitEmbedding model: {multimodal_model.fastvit_model.training}\")\n",
    "    print(f\"BERTEmbedding model: {multimodal_model.bert_model.training}\")\n",
    "\n",
    "    print(f\"Multimodal model: {multimodal_model.training}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfef7e3ccad9ac15",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(EPOCHS=100):\n",
    "    best_val_loss = float(\"inf\")\n",
    "    multimodal_model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        multimodal_model.train()\n",
    "        # print_model_statuses()\n",
    "        train_losses = []\n",
    "        all_train_predictions = []\n",
    "        all_train_ground_truths = []\n",
    "\n",
    "        for batch in tqdm(train_loader):\n",
    "            images, input_ids, attention_mask, structured_data, targets = [b.to(device) for b in batch]\n",
    "            targets = targets.view(-1, 1)\n",
    "\n",
    "            outputs = multimodal_model(images, input_ids, attention_mask, structured_data)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            unnorm_outputs = target_scaler.inverse_transform(outputs.cpu().detach().numpy())\n",
    "            unnorm_targets = target_scaler.inverse_transform(targets.cpu().detach().numpy())\n",
    "\n",
    "            all_train_predictions.extend(unnorm_outputs)\n",
    "            all_train_ground_truths.extend(unnorm_targets)\n",
    "\n",
    "        train_metrics = compute_metrics(all_train_predictions, all_train_ground_truths)\n",
    "        metrics_history[\"train_mae\"].append(train_metrics[\"MAE\"])\n",
    "        metrics_history[\"train_mse\"].append(train_metrics[\"MSE\"])\n",
    "        metrics_history[\"train_rmse\"].append(train_metrics[\"RMSE\"])\n",
    "        metrics_history[\"train_r2\"].append(train_metrics[\"R2\"])\n",
    "\n",
    "        avg_train_loss = np.sum(train_losses) / len(train_loader)\n",
    "        history[\"train_loss\"].append(avg_train_loss)\n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {avg_train_loss}\")\n",
    "        print(f\"Epoch {epoch + 1}, Train Metrics: {train_metrics}\")\n",
    "\n",
    "        multimodal_model.eval()\n",
    "        # print_model_statuses()\n",
    "        with torch.no_grad():\n",
    "            validation_losses = []\n",
    "            all_test_predictions = []\n",
    "            all_test_ground_truths = []\n",
    "            for batch in tqdm(test_loader):\n",
    "                images, input_ids, attention_mask, structured_data, targets = [b.to(device) for b in batch]\n",
    "                targets = targets.view(-1, 1)\n",
    "\n",
    "                outputs = multimodal_model(images, input_ids, attention_mask, structured_data)\n",
    "                loss = criterion(outputs, targets)\n",
    "                validation_losses.append(loss.item())\n",
    "\n",
    "                unnorm_outputs = target_scaler.inverse_transform(outputs.cpu().detach().numpy())\n",
    "                unnorm_targets = target_scaler.inverse_transform(targets.cpu().detach().numpy())\n",
    "\n",
    "                all_test_predictions.extend(unnorm_outputs)\n",
    "                all_test_ground_truths.extend(unnorm_targets)\n",
    "\n",
    "            avg_val_loss = np.sum(validation_losses) / len(test_loader)\n",
    "            history[\"test_loss\"].append(avg_val_loss)\n",
    "\n",
    "            test_metrics = compute_metrics(all_test_predictions, all_test_ground_truths)\n",
    "            metrics_history[\"test_mae\"].append(test_metrics[\"MAE\"])\n",
    "            metrics_history[\"test_mse\"].append(test_metrics[\"MSE\"])\n",
    "            metrics_history[\"test_rmse\"].append(test_metrics[\"RMSE\"])\n",
    "            metrics_history[\"test_r2\"].append(test_metrics[\"R2\"])\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}, Validation Loss: {avg_val_loss}\")\n",
    "            print(f\"Epoch {epoch + 1}, Test Metrics: {test_metrics}\")\n",
    "\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(multimodal_model.state_dict(), MULTIMODAL_MODEL_PATH)\n",
    "                print(f\"Epoch {epoch + 1}: New best test loss: {best_val_loss}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccefc1fdce37d2e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train(3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a31eb282ff22e6fa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_loss_and_metrics(history, metrics_history, SLICE_START=20)\n",
    "print_metrics_table(metrics_history)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "326f6fc681ac4367",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
