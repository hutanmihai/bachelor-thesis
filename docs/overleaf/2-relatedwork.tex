\chapter{Related Work}

This chapter presents an overview of related work in applying machine learning to the automotive sector. It is structured into three distinct sections:

\begin{enumerate}
    \item \textbf{Data Relevance in Car Pricing}: This section explores studies and findings on the impact of various data features on car pricing, highlighting which factors are most influential in determining a vehicle's value.
    \item \textbf{Regression Models for Car Prices}: The second section examines earlier regression models used for predicting car prices, discussing their methodologies, strengths, and limitations.
    \item \textbf{Recent Multimodal Approaches}: The final section focuses on recent advancements in multimodal approaches, which combine various types of data (e.g., textual descriptions, images).
\end{enumerate}

\section{Data Relevance in Car Pricing}
Following our data scraping process, we encountered one of the most significant challenges of our thesis: programmatically curating the data. Our dataset, though extensive, was prone to errors due to various issues such as human mistakes, incomplete fields, and inconsistencies inherent in the scraping process. This necessitated rigorous cleaning decisions, detailed in \hyperref[sec:data-cleaning]{Section 3.3}. Despite concerns about the potential loss of important information during curation, further analysis and recent field research confirmed that we successfully retained the most crucial details about the cars and even more. This allowed us to proceed confidently with our approach.
\\

Due to his comprehensive research in his recently defended Master's Thesis \cite{czech}, Jan Žiačik showcased a detailed overview of the determinants of used car prices. Similar to recent studies in the field, he proved that there are a lot of variables in determining the price of a used car, but some of them are more important than others. A few of the most significant ones he discovered are the year of production, fuel type, whether the gearbox is automatic or manual, and fuel consumption. Despite our severe data cleaning process, we managed to keep all these values except the consumption for our model.

We have observed a trend where custom equipment is often overlooked in previous studies and models. The price of a car can vary significantly due to its customized look or functionality. For example, a car with a sunroof can be priced up to €10,000 higher than a similar car without one, depending on the manufacturer. This seemingly small difference can notably impact both the initial selling price and the resale value.

In the paper "Machine Learning for Predicting Used
Car Resale Prices Using Granular Vehicle Equipment Information" \cite{granular}, the authors also remarked this issue and conducted experiments to show the relevance of custom options of the cars regarding their selling price. They discovered a 3.27\% improvement in their performance metric (i.e., mean absolute error) using this additional data.

After analyzing their study, we have discovered some limitations. While taking into consideration these small details, they still tend to generalize them. Their approach is mapping all the details into 18 predefined categories for custom options. While this solution still brought valuable insights to their model, we believe there is a loss of information. One example presented in their paper is that they map an option initially presented as "two-zone climatronic" to the general category "air conditioning." We want to improve upon this approach further and use the information from advertisements down to the last detail.

\section{Regression Models for Car Prices}
Although numerous studies have explored using machine learning to predict car prices, no universal solution has been identified. Approaches have ranged from classic methods like linear regression and random forest regression to advanced deep learning neural networks. Platforms such as Kaggle \cite{kaggle} have hosted various competitions, driving significant advancements in this field. However, these efforts often focus on specialized datasets, limited to specific manufacturers, regions, or time periods. This narrow scope hampers the generalizability of models, highlighting the need for more comprehensive approaches that can handle diverse and heterogeneous data.
\\

In the realm of classic methods, linear regression provides a straightforward and interpretable approach but often falls short in capturing complex, non-linear relationships. Random forest regression, on the other hand, offers improved accuracy by combining multiple decision trees at the cost of reduced interpretability.
\\

Deep learning neural networks represent a leap forward, capable of modeling intricate patterns and interactions within the data. Studies leveraging convolutional neural networks (CNNs) have shown promise, particularly in handling high-dimensional, unstructured data.

\section{Recent Multimodal Approaches}
The rise of transformers in machine learning has catalyzed a shift towards multimodal approaches, integrating diverse types of information such as text, audio, and images. This trend aligns with the broader goal of achieving Artificial General Intelligence (AGI), which requires a comprehensive understanding of varied data modalities. Our objective is to apply these cutting-edge techniques to the domain of car price prediction.
\\

Despite limited research specifically addressing multimodal approaches for car price prediction, insights from other fields underscore the potential of this method. For instance, multimodal models have significantly improved performance in tasks like image captioning, sentiment analysis, and medical diagnostics by effectively combining textual and visual data.

One study particularly relevant to our research is "Multi-modal Machine Learning for Vehicle Rating Predictions Using Image, Text, and Parametric Data" \cite{su2023multi}, which presents a multimodal regression model to predict car rating scores. Their approach integrates a Multilayer Perceptron (MLP) for numerical data, BERT for textual data, and a CNN with self-attention mechanisms for visual data. This combination allowed them to capture complex interactions across different data types, yielding impressive results on a well-curated dataset. 

Our approach will be quite similar, with a few key differences. One major difference lies in the image encoder: we will use FastVit, which we believe will perform better for our diverse set of images, compared to the more structured dataset used by the original authors. Additionally, there are variations in our training methodology and minor architectural choices, such as input layer sizes and dropout values. A significant distinction is in our training approach: while the original authors trained their architecture end-to-end, we opted to train the components separately.
